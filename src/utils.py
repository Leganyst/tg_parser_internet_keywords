import re
from rapidfuzz import fuzz
import spacy
from loguru import logger
from src.keywords import load_keywords
from src.config import KEYWORDS_FILE

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –æ–¥–∏–Ω —Ä–∞–∑
nlp = spacy.load("ru_core_news_sm")

# –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä—É–ø–ø—ã –¥–ª—è –∫–ª—é—á–µ–π; –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –ø–æ —Å–≤–æ–µ–º—É —Å–ª–æ–≤–∞—Ä—é
RAW_GROUP_MAP = {
    # === NETWORK ===
    "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç":         "network",
    "—Å–µ—Ç—å":             "network",
    "—Å–µ—Ç–µ–≤–æ–π":          "network",
    "–≤–∞–π—Ñ–∞–π":           "network",
    "wi-fi":            "network",
    "–≤–∞–π-—Ñ–∞–π":          "network",
    "—Ä–æ—É—Ç–µ—Ä":           "network",
    "–º–æ–¥–µ–º":            "network",
    "–∫–∞–±–µ–ª—å":           "network",
    "–ø–∏–Ω–≥":             "network",
    "dns":              "network",
    "ip":               "network",
    "–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ":      "network",
    "–ª–æ–∫–∞–ª–∫–∞":          "network",
    "–∏–Ω–µ—Ç":             "network",
    "–¥–æ—Å—Ç—É–ø":           "network",

    # === OPERATOR NAMES ===
    "—Ä–æ—Å—Ç–µ–ª–µ–∫–æ–º":       "operator",
    "—Ä—Ç–∫–æ–º":            "operator",
    "–¥–æ–º—Ä—É":            "operator",
    "–¥–æ–º.—Ä—É":           "operator",
    "–±–∏–ª–∞–π–Ω":           "operator",
    "–º—Ç—Å":              "operator",
    "–º–µ–≥–∞—Ñ–æ–Ω":          "operator",
    "—Ç—Ç–∫":              "operator",
    "—é–≥-–ª–∏–Ω–∫":          "operator",
    "–π–æ—Ç–∞":             "operator",
    "–∏–Ω—Ñ–æ–ª–∏–Ω–∫":         "operator",
    "–∏–Ω—Ç–µ—Ä—Å–≤—è–∑—å":       "operator",
    "–æ–±–∏—Ç":             "operator",

    # === CONNECTION REQUESTS ===
    "—Ö–æ—á—É –ø–æ–¥–∫–ª—é—á–∏—Ç—å":          "connect",
    "–∫–∞–∫ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è":         "connect",
    "–∑–∞—è–≤–∫–∞ –Ω–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ":    "connect",
    "–æ—Ñ–æ—Ä–º–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ":     "connect",
    "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è":   "connect",
    "–º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è":       "connect",
    "–≥–¥–µ –ø–æ–¥–∫–ª—é—á–∏—Ç—å":           "connect",
    "–∫—É–¥–∞ –æ–±—Ä–∞—â–∞—Ç—å—Å—è":          "connect",
    "–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞—è–≤–∫—É":          "connect",
    "–ø–æ–¥–∫–ª—é—á–∏—Ç—å":               "connect",
    "–ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è":             "connect",
    "–ø–æ–¥–∫–ª—é—á–∞—é—Å—å":              "connect",
    "–ø–æ–¥–∫–ª—é—á–∞—é":                "connect",
    "–ø–æ–¥–∫–ª—é—á–∫–∞":                "connect",
    "—Å–º–µ–Ω–∏—Ç—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞":       "connect",
    "—Å–º–µ–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞":        "connect",
    "–∏—â—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É":         "connect",
    "–ø–µ—Ä–µ–π—Ç–∏ –Ω–∞":               "connect",
    "–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞":             "connect",
    "—Å—Ä–∞–≤–Ω–∏–≤–∞—é":                "connect",
    "–∏—â—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞":           "connect",
    "—á—Ç–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å":           "connect",
    "–ø–µ—Ä–µ–µ–∑–∂–∞—é":                "connect",

    # === COMPLAINTS ===
    "–ø–ª–æ—Ö–æ–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç":          "complaint",
    "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç":    "complaint",
    "–Ω–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞":            "complaint",
    "–∏–Ω–µ—Ç –ª–∞–≥–∞–µ—Ç":              "complaint",
    "–ø–∞–¥–∞–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç":          "complaint",
    "–Ω–∏–∑–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å":          "complaint",
    "–º–µ–¥–ª–µ–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç":        "complaint",
    "—á–∞—Å—Ç—ã–µ –æ–±—Ä—ã–≤—ã":            "complaint",
    "–ø—Ä–æ–ø–∞–¥–∞–µ—Ç —Å–≤—è–∑—å":          "complaint",
    "–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –ª–∞–≥–∏":          "complaint",
    "–æ–±—Ä—ã–≤—ã":                   "complaint",
    "—Å–±–æ–π —Å–µ—Ç–∏":                "complaint",
    "–Ω–µ—Ç —Å–∏–≥–Ω–∞–ª–∞":              "complaint",
    "–Ω–µ –≥—Ä—É–∑–∏—Ç":                "complaint",
    "–≤–æ–æ–±—â–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç":       "complaint",
    "–∑–∞–≤–∏—Å–∞–µ—Ç":                 "complaint",
    "–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞—é –∫–∞–∂–¥—ã–π –¥–µ–Ω—å": "complaint",

    # === OTHER SUPPORT/FORMAL ===
    "–∑–∞—è–≤–∫–∞":                   "connect",
    "–∞–¥—Ä–µ—Å":                    "connect",
    "–æ—Å—Ç–∞–≤–∏–ª –∑–∞—è–≤–∫—É":           "connect",
    "–∑–∞—è–≤–ª–µ–Ω–∏–µ":                "connect",
    "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ":               "connect",
    "–¥–æ–≥–æ–≤–æ—Ä":                  "connect",
    "–ø–æ–¥–¥–µ—Ä–∂–∫–∞":               "connect",
    "—Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞":            "connect",
}

def normalize_group_map(raw_map: dict[str, str]) -> dict[str, str]:
    norm_map = {}
    for word, group in raw_map.items():
        doc = nlp(word)
        for token in doc:
            if token.is_alpha:
                norm_map[token.lemma_.lower()] = group
    return norm_map

GROUP_MAP = normalize_group_map(RAW_GROUP_MAP)  # RAW_GROUP_MAP ‚Äî —Å–ª–æ–≤–∞—Ä—å —Å —Ñ–æ—Ä–º–∞–º–∏ —Å–ª–æ–≤

SPAM_PATTERNS = [
    r"\+?\d{7,}",                       # —Ç–µ–ª–µ—Ñ–æ–Ω
    r"https?://\S+",                   # —Å—Å—ã–ª–∫–∞
    r"\b\S+@\S+\.\S+\b",               # email
    r"—Ä–∞–±–æ—Ç–∞ –Ω–∞ –¥–æ–º—É",                 # —à–∞–±–ª–æ–Ω –≤–∞–∫–∞–Ω—Å–∏–∏
    r"—Ä–∞–±–æ—Ç–∞ –æ–Ω–ª–∞–π–Ω",                  # —É–¥–∞–ª—ë–Ω–∫–∞
    r"–≥–∏–±–∫–∏–π –≥—Ä–∞—Ñ–∏–∫",                  # –≥—Ä–∞—Ñ–∏–∫
    r"–¥–æ—Ö–æ–¥ –æ—Ç \d+",                   # –∑–∞–º–∞–Ω—É—Ö–∞ –¥–µ–Ω—å–≥–∞–º–∏
    r"–ø–æ –¥–æ–≥–æ–≤–æ—Ä—É",                    # –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ
    r"—Ç—Ä–µ–±—É—é—Ç—Å—è –º–µ–Ω–µ–¥–∂–µ—Ä—ã",            # –º–∞—Å—Å–æ–≤—ã–π –Ω–∞–±–æ—Ä
    r"–∏—â–µ—à—å —Ä–∞–±–æ—Ç—É –º–µ—á—Ç—ã",             # —à–∞–±–ª–æ–Ω –≤–æ–≤–ª–µ—á–µ–Ω–∏—è
    r"–≤—Å—Ç—É–ø–∏ –≤ –º–æ—é –∫–æ–º–∞–Ω–¥—É",           # MLM —Å—Ç–∏–ª—å
    r"–∑–∞—Ä–∞–±–æ—Ç–æ–∫ –±–µ–∑ –≤–ª–æ–∂–µ–Ω–∏–π",         # –ª–æ—Ö–æ—Ç—Ä–æ–Ω
    r"–±–µ–∑ –≤–ª–æ–∂–µ–Ω–∏[—è–µ]",                # –±–µ–∑ –≤–ª–æ–∂–µ–Ω–∏–π (–≥–∏–±–∫–æ)
    r"–±–µ–∑ –æ–ø—ã—Ç–∞",                      # —à–∞–±–ª–æ–Ω –æ—Ñ—Ñ–µ—Ä–∞
    r"–æ–±—É—á–µ–Ω–∏–µ.*–±–µ—Å–ø–ª–∞—Ç–Ω–æ",            # –æ–±–µ—â–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
    r"–ø—Ä–æ–¥–∞–∂–∞ —Å–ø–ª–∏—Ç",                  # —Ä–µ–∫–ª–∞–º–∞
    r"—Å–ø–ª–∏—Ç —Å–∏—Å—Ç–µ–º",                   # HVAC —Ç–µ—Ö–Ω–∏–∫–∞
    r"–∞–∫—Ü–∏—è",                          # —Å–∫–∏–¥–∫–∏
    r"—É—Å–ø–µ–π.*–∫—É–ø–∏—Ç—å",                  # —Å—Ä–æ—á–Ω–æ—Å—Ç—å
    r"–∑–∞–±—Ä–æ–Ω–∏—Ä—É–π.*–º–µ—Å—Ç–æ",              # ‚Äú–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ‚Äù
    r"—Ä–∞–±–æ—Ç–∞ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞—Ö",          # scam recruitment
    r"—Å—Ç–∞–≤–∫–∏ –Ω–∞ —Å–ø–æ—Ä—Ç",                # –±—É–∫–º–µ–∫–µ—Ä–∫–∞
    r"–ø—Ä–æ–º–æ–∫–æ–¥",                       # –∞–∫—Ü–∏–∏/–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ
    r"–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–µ–º–∏—è",         # –æ—Ñ—Ñ–µ—Ä
    r"–±–µ—Å–ø–ª–∞—Ç–Ω–∞—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è",         # –≤–æ–≤–ª–µ—á–µ–Ω–∏–µ
    r"–ø–µ–Ω—Å–∏–æ–Ω–µ—Ä–∞–º|—Å—Ç—É–¥–µ–Ω—Ç–∞–º|–¥–µ–∫—Ä–µ—Ç–µ",  # —Ü–µ–ª–µ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    r"–æ–ø–ª–∞—Ç–∞ –ø–æ —Ñ–∞–∫—Ç—É",                # —Ç—Ä–∏–≥–≥–µ—Ä –ø—Ä–æ–¥–∞–∂
    r"–≥—Ä—É–∑–æ–ø–µ—Ä–µ–≤–æ–∑–∫[–∞–∏]",              # —É—Å–ª—É–≥–∏ –ø–µ—Ä–µ–≤–æ–∑–∫–∏
    r"–¥–æ–º–∞—à–Ω–∏–µ –ø–µ—Ä–µ–µ–∑–¥—ã",              # —Ç–æ –∂–µ
    r"—Ä–µ–º–æ–Ω—Ç —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫–∏",              # —à–∞–±–ª–æ–Ω–Ω–∞—è —É—Å–ª—É–≥–∞
    r"–ø–µ—Ä–µ–µ–∑–¥—ã.*—Ä–∞—Å—á–∏—Å—Ç–∫–∞",            # –Ω–∞–±–æ—Ä —É—Å–ª—É–≥
    r"–≤—ã–µ–∑–¥.*–∂–∏–≤–æ—Ç–Ω—ã—Ö",               # –ª–æ–≥–∏—Å—Ç–∏–∫–∞/—É—Å–ª—É–≥–∏
    r"–∑–∞–±–µ—Ä—ë–º –ø–µ—Ä–µ–¥–∞—á–∏",               # –ª–æ–≥–∏—Å—Ç–∏–∫–∞
    r"üõ†|üõú|üìå|üî•|‚úÖ|‚ÄºÔ∏è|üìò|üìï|üöå|üöö|üöÄ|üéÅ",  # —ç–º–æ–¥–∑–∏
    r"[üÖ∞-üÜéüÖ±Ô∏èüÜòüÖæÔ∏èüÜö]",                # ‚Äú–æ–±–≤–æ–¥–∫–∏‚Äù –±—É–∫–≤
    r"(?:—Ä–∞–±–æ—Ç–∞|–ø–æ–¥—Ä–∞–±–æ—Ç–∫–∞)[^.]{0,10}‚ùó", # —Ä–µ–∫–ª–∞–º–∞ —Ä–∞–±–æ—Ç—ã —Å –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–µ–º
    r"—Ä–∞–∑–¥–∞—á–∞\s+—Ñ–ª–∞–µ—Ä",                 # –æ–±—ä—è–≤–ª–µ–Ω–∏—è –æ —Ñ–ª–∞–µ—Ä–∞—Ö
    r"—Ñ–ª–∞–µ—Ä",                            # –ª—é–±—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ñ–ª–∞–µ—Ä–æ–≤
    r"—Ä–∞–±–æ—Ç–∞ –∏–∑ –¥–æ–º–∞",                  # –æ–±–æ–±—â—ë–Ω–Ω–∞—è —É–¥–∞–ª—ë–Ω–∫–∞
    r"–∑–∞—Ä–∞–±–æ—Ç(–æ–∫|–∞—Ç—å)",                 # —á–∞—Å—Ç—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è —Å–ø–∞–º–∞
    r"–∑–∞–ø–∏—à–∏—Å—å.*@|–Ω–∞–ø–∏—à–∏.*@",          # –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ —á–µ—Ä–µ–∑ —Ç–µ–≥–∏
    r"–∫–∞—Ç–∞–ª–æ–≥.*–≥—Ä—É–ø–ø",                 # –∫–∞—Ç–∞–ª–æ–≥–∏ —Ä–∞—Å—Å—ã–ª–æ–∫
    r"–±–æ–ª–µ–µ \d+ –≥—Ä—É–ø–ø",                 # —Ä–∞—Å—Å—ã–ª–æ—á–Ω—ã–µ –∞–Ω–æ–Ω—Å—ã
    r"–ø—Ä–∞–≤–∏–ª–∞.*—Ä–∞–∑–º–µ—â–∞–π",              # –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã / –±–∏–∑–Ω–µ—Å-—á–∞—Ç—ã
    r"—Ä–µ–∫–ª–∞–º.*–≥—Ä—É–ø–ø",                   # –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ –≥—Ä—É–ø–ø
    r"–ø–æ–¥–¥–µ—Ä–∂–∫–∞.*–æ–±—É—á–µ–Ω–∏",             # hr-–ø–æ–¥–¥–µ—Ä–∂–∫–∞
    r"–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞",      # –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è/–Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞
    r"—Ç–∞—Ä–∏—Ñ—ã –Ω–∞.*—É—Å–ª—É–≥–∏",              # –Ω–µ —Å–≤—è–∑—å, –∞ —Ä–µ–∫–ª–∞–º–∞
    r"—Ä–∞—Å—Å—ã–ª–∫",                         # —Ä–∞—Å—Å—ã–ª–∫–∞ —Ä–µ–∫–ª–∞–º—ã
]

# –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω—ã —Å–ø–∞–º–∞ –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
SPAM_REGEX = [re.compile(p, flags=re.IGNORECASE) for p in SPAM_PATTERNS]


# –ü–æ—Ä–æ–≥–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
FUZZ_THRESH     = 85   # –ø—Ä–æ—Ü–µ–Ω—Ç –¥–ª—è fuzzy
MIN_MATCHES     = 1    # —Ç—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 1 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–∞
# —Ç—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 2 —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä—É–ø–ø –ø—Ä–∏ –≥—Ä—É–ø–ø–æ–≤–æ–º —Ñ–∏–ª—å—Ç—Ä–µ
MIN_GROUPS      = 2    # –∏–∑ –º–∏–Ω–∏–º—É–º 2 —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä—É–ø–ø
MAX_TOKEN_DIST  = 10   # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª—é—á–µ–≤—ã–º–∏ –ª–µ–º–º–∞–º–∏


def simple_keyword_match(text: str) -> list[str] | None:
    """
    –§–∏–ª—å—Ç—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞:
      ‚Äì –û—Ç—Å–µ–∫–∞–µ—Ç —Å–ø–∞–º-–æ–±—ä—è–≤–ª–µ–Ω–∏—è –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º/—Å—Å—ã–ª–∫–∞–º
      ‚Äì –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ spaCy
      ‚Äì –ù–∞—Ö–æ–¥–∏—Ç multi-word –∏ single-word –∫–ª—é—á–∏ (exact & fuzzy)
      ‚Äì –¢—Ä–µ–±—É–µ—Ç –º–∏–Ω–∏–º—É–º 2 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≥—Ä—É–ø–ø
      ‚Äì –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –±–ª–∏–∑–∫–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (‚â§ MAX_TOKEN_DIST —Ç–æ–∫–µ–Ω–æ–≤)
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π –∏–ª–∏ None.
    """
    text = str(text)
    t_lower = text.lower()

    # 0) –°–ø–∞–º-—Ñ–∏–ª—å—Ç—Ä
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∞–º —Å –ø–æ–º–æ—â—å—é —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö regex
    for spam_re in SPAM_REGEX:
        if spam_re.search(t_lower):
            logger.debug(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ —Å–ø–∞–º –ø–æ —à–∞–±–ª–æ–Ω—É: {spam_re.pattern}")
            return None
        
    # 1) –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª—é—á–µ–π
    raw_keywords = load_keywords(KEYWORDS_FILE)
    kw_single = {}   # –ª–µ–º–º–∞ ‚Üí –æ—Ä–∏–≥–∏–Ω–∞–ª
    kw_multi  = []   # [(tuple(–ª–µ–º–º...), –æ—Ä–∏–≥–∏–Ω–∞–ª), ...]

    for kw in raw_keywords:
        lemmas = tuple(token.lemma_.lower() for token in nlp(kw) if token.is_alpha)
        if not lemmas:
            continue
        if len(lemmas) == 1:
            kw_single.setdefault(lemmas[0], kw)
        else:
            kw_multi.append((lemmas, kw))

    # 2) –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    doc    = nlp(text)
    lemmas = [token.lemma_.lower() for token in doc if token.is_alpha]
    
    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—ã –ø–æ –ª–µ–º–º–∞–º (–∏ —Ñ—Ä–∞–∑–∞–º –∏–∑ –ª–µ–º–º)
    matched_groups = set()
    text_lemmas_str = " ".join(lemmas)
    for pattern, group in GROUP_MAP.items():
        if pattern in text_lemmas_str:
            matched_groups.add(group)
            
    matches      = set()
    groups_found = set()
    positions    = []

    # 3) Multi-word match
    for kw_lem, original in kw_multi:
        L = len(kw_lem)
        if L > len(lemmas):
            continue
        for i in range(len(lemmas) - L + 1):
            window = tuple(lemmas[i: i + L])
            if window == kw_lem:
                matches.add(original)
                grp = GROUP_MAP.get(original, "other")
                groups_found.add(grp)
                positions.append(i)
                logger.info(f"Multi-word match '{original}' at pos {i}")
                break

    # 4) Single-word exact match
    for idx, lemma in enumerate(lemmas):
        if lemma in kw_single:
            original = kw_single[lemma]
            matches.add(original)
            grp = GROUP_MAP.get(original, "other")
            groups_found.add(grp)
            positions.append(idx)
            logger.info(f"Single exact match '{original}' at pos {idx}")

    # 5) Single-word fuzzy match (—Ç—Ä–µ–±—É–µ–º —Ö–æ—Ç—è –±—ã –¥–≤–∞ —Ç–∞–∫–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)
    fuzzy_hits = 0
    for idx, lemma in enumerate(lemmas):
        for key_lem, original in kw_single.items():
            ratio = fuzz.ratio(lemma, key_lem)
            if ratio >= FUZZ_THRESH:
                fuzzy_hits += 1
                if fuzzy_hits > 1:
                    matches.add(original)
                    grp = GROUP_MAP.get(original, "other")
                    groups_found.add(grp)
                    positions.append(idx)
                    logger.info(
                        f"Fuzzy match '{original}' for lemma='{lemma}' "
                        f"vs key='{key_lem}', ratio={ratio} at pos {idx}"
                    )
                break

    # 6) –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä: –¥–≤–∞ –ø—É—Ç–∏ –∫ –ø—Ä–∏–Ω—è—Ç–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è
    # 1) –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä—è–º—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    if len(matches) >= MIN_MATCHES:
        logger.info(f"–ü—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: matches={matches}")
        return list(matches)
    # 2) –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä—É–ø–ø –∏ –±–ª–∏–∑–æ—Å—Ç—å –ø–æ –ø–æ–∑–∏—Ü–∏–∏
    if len(matched_groups) >= MIN_GROUPS and len(groups_found) >= MIN_GROUPS \
       and positions and (max(positions) - min(positions) <= MAX_TOKEN_DIST):
        logger.info(
            f"–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å—Ç—Ä: matched_groups={matched_groups}, "
            f"groups_found={groups_found}, positions={positions}"
        )
        return list(matches)
    # –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –æ—Ç–∫–ª–æ–Ω—è–µ–º
    logger.debug(f"–û—Ç–∫–ª–æ–Ω–µ–Ω–æ: matches={matches}, matched_groups={matched_groups}, groups_found={groups_found}, positions={positions}")
    return None