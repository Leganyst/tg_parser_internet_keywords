import re
from rapidfuzz import fuzz
import spacy
from loguru import logger
from src.keywords import load_keywords
from src.config import KEYWORDS_FILE

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ spaCy Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð·
nlp = spacy.load("ru_core_news_sm")

# Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð´Ð»Ñ ÐºÐ»ÑŽÑ‡ÐµÐ¹; Ð·Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ Ð¿Ð¾ ÑÐ²Ð¾ÐµÐ¼Ñƒ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŽ
RAW_GROUP_MAP = {
    # === NETWORK ===
    "Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚":         "network",
    "ÑÐµÑ‚ÑŒ":             "network",
    "ÑÐµÑ‚ÐµÐ²Ð¾Ð¹":          "network",
    "Ð²Ð°Ð¹Ñ„Ð°Ð¹":           "network",
    "wi-fi":            "network",
    "Ð²Ð°Ð¹-Ñ„Ð°Ð¹":          "network",
    "Ñ€Ð¾ÑƒÑ‚ÐµÑ€":           "network",
    "Ð¼Ð¾Ð´ÐµÐ¼":            "network",
    "ÐºÐ°Ð±ÐµÐ»ÑŒ":           "network",
    "Ð¿Ð¸Ð½Ð³":             "network",
    "dns":              "network",
    "ip":               "network",
    "Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ":      "network",
    "Ð»Ð¾ÐºÐ°Ð»ÐºÐ°":          "network",
    "Ð¸Ð½ÐµÑ‚":             "network",
    "Ð´Ð¾ÑÑ‚ÑƒÐ¿":           "network",

    # === OPERATOR NAMES ===
    "Ñ€Ð¾ÑÑ‚ÐµÐ»ÐµÐºÐ¾Ð¼":       "operator",
    "Ñ€Ñ‚ÐºÐ¾Ð¼":            "operator",
    "Ð´Ð¾Ð¼Ñ€Ñƒ":            "operator",
    "Ð´Ð¾Ð¼.Ñ€Ñƒ":           "operator",
    "Ð±Ð¸Ð»Ð°Ð¹Ð½":           "operator",
    "Ð¼Ñ‚Ñ":              "operator",
    "Ð¼ÐµÐ³Ð°Ñ„Ð¾Ð½":          "operator",
    "Ñ‚Ñ‚Ðº":              "operator",
    "ÑŽÐ³-Ð»Ð¸Ð½Ðº":          "operator",
    "Ð¹Ð¾Ñ‚Ð°":             "operator",
    "Ð¸Ð½Ñ„Ð¾Ð»Ð¸Ð½Ðº":         "operator",
    "Ð¸Ð½Ñ‚ÐµÑ€ÑÐ²ÑÐ·ÑŒ":       "operator",
    "Ð¾Ð±Ð¸Ñ‚":             "operator",

    # === CONNECTION REQUESTS ===
    "Ñ…Ð¾Ñ‡Ñƒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ":          "connect",
    "ÐºÐ°Ðº Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒÑÑ":         "connect",
    "Ð·Ð°ÑÐ²ÐºÐ° Ð½Ð° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ":    "connect",
    "Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ":     "connect",
    "Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ":   "connect",
    "Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒÑÑ":       "connect",
    "Ð³Ð´Ðµ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ":           "connect",
    "ÐºÑƒÐ´Ð° Ð¾Ð±Ñ€Ð°Ñ‰Ð°Ñ‚ÑŒÑÑ":          "connect",
    "Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ð·Ð°ÑÐ²ÐºÑƒ":          "connect",
    "Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ":               "connect",
    "Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒÑÑ":             "connect",
    "Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÑŽÑÑŒ":              "connect",
    "Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÑŽ":                "connect",
    "Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐºÐ°":                "connect",
    "ÑÐ¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°":       "connect",
    "ÑÐ¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°":        "connect",
    "Ð¸Ñ‰Ñƒ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñƒ":         "connect",
    "Ð¿ÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð½Ð°":               "connect",
    "Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð°":             "connect",
    "ÑÑ€Ð°Ð²Ð½Ð¸Ð²Ð°ÑŽ":                "connect",
    "Ð¸Ñ‰Ñƒ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°":           "connect",
    "Ñ‡Ñ‚Ð¾ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ":           "connect",
    "Ð¿ÐµÑ€ÐµÐµÐ·Ð¶Ð°ÑŽ":                "connect",

    # === COMPLAINTS ===
    "Ð¿Ð»Ð¾Ñ…Ð¾Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚":          "complaint",
    "Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚":    "complaint",
    "Ð½ÐµÑ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ð°":            "complaint",
    "Ð¸Ð½ÐµÑ‚ Ð»Ð°Ð³Ð°ÐµÑ‚":              "complaint",
    "Ð¿Ð°Ð´Ð°ÐµÑ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚":          "complaint",
    "Ð½Ð¸Ð·ÐºÐ°Ñ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ":          "complaint",
    "Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚":        "complaint",
    "Ñ‡Ð°ÑÑ‚Ñ‹Ðµ Ð¾Ð±Ñ€Ñ‹Ð²Ñ‹":            "complaint",
    "Ð¿Ñ€Ð¾Ð¿Ð°Ð´Ð°ÐµÑ‚ ÑÐ²ÑÐ·ÑŒ":          "complaint",
    "Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ñ‹Ðµ Ð»Ð°Ð³Ð¸":          "complaint",
    "Ð¾Ð±Ñ€Ñ‹Ð²Ñ‹":                   "complaint",
    "ÑÐ±Ð¾Ð¹ ÑÐµÑ‚Ð¸":                "complaint",
    "Ð½ÐµÑ‚ ÑÐ¸Ð³Ð½Ð°Ð»Ð°":              "complaint",
    "Ð½Ðµ Ð³Ñ€ÑƒÐ·Ð¸Ñ‚":                "complaint",
    "Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚":       "complaint",
    "Ð·Ð°Ð²Ð¸ÑÐ°ÐµÑ‚":                 "complaint",
    "Ð¿ÐµÑ€ÐµÐ·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ": "complaint",

    # === OTHER SUPPORT/FORMAL ===
    "Ð·Ð°ÑÐ²ÐºÐ°":                   "connect",
    "Ð°Ð´Ñ€ÐµÑ":                    "connect",
    "Ð¾ÑÑ‚Ð°Ð²Ð¸Ð» Ð·Ð°ÑÐ²ÐºÑƒ":           "connect",
    "Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð¸Ðµ":                "connect",
    "Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ":               "connect",
    "Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€":                  "connect",
    "Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°":               "connect",
    "Ñ‚ÐµÑ…Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°":            "connect",
}

def normalize_group_map(raw_map: dict[str, str]) -> dict[str, str]:
    norm_map = {}
    for word, group in raw_map.items():
        doc = nlp(word)
        for token in doc:
            if token.is_alpha:
                norm_map[token.lemma_.lower()] = group
    return norm_map

GROUP_MAP = normalize_group_map(RAW_GROUP_MAP)  # RAW_GROUP_MAP â€” ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ñ„Ð¾Ñ€Ð¼Ð°Ð¼Ð¸ ÑÐ»Ð¾Ð²

SPAM_PATTERNS = [
    r"\+?\d{7,}",                       # Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½
    r"https?://\S+",                   # ÑÑÑ‹Ð»ÐºÐ°
    r"\b\S+@\S+\.\S+\b",               # email
    r"Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ð½Ð° Ð´Ð¾Ð¼Ñƒ",                 # ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸
    r"Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ð¾Ð½Ð»Ð°Ð¹Ð½",                  # ÑƒÐ´Ð°Ð»Ñ‘Ð½ÐºÐ°
    r"Ð³Ð¸Ð±ÐºÐ¸Ð¹ Ð³Ñ€Ð°Ñ„Ð¸Ðº",                  # Ð³Ñ€Ð°Ñ„Ð¸Ðº
    r"Ð´Ð¾Ñ…Ð¾Ð´ Ð¾Ñ‚ \d+",                   # Ð·Ð°Ð¼Ð°Ð½ÑƒÑ…Ð° Ð´ÐµÐ½ÑŒÐ³Ð°Ð¼Ð¸
    r"Ð¿Ð¾ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ñƒ",                    # Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ
    r"Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑÑ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ñ‹",            # Ð¼Ð°ÑÑÐ¾Ð²Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€
    r"Ð¸Ñ‰ÐµÑˆÑŒ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ Ð¼ÐµÑ‡Ñ‚Ñ‹",             # ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð²Ð¾Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ
    r"Ð²ÑÑ‚ÑƒÐ¿Ð¸ Ð² Ð¼Ð¾ÑŽ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ",           # MLM ÑÑ‚Ð¸Ð»ÑŒ
    r"Ð·Ð°Ñ€Ð°Ð±Ð¾Ñ‚Ð¾Ðº Ð±ÐµÐ· Ð²Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹",         # Ð»Ð¾Ñ…Ð¾Ñ‚Ñ€Ð¾Ð½
    r"Ð±ÐµÐ· Ð²Ð»Ð¾Ð¶ÐµÐ½Ð¸[ÑÐµ]",                # Ð±ÐµÐ· Ð²Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹ (Ð³Ð¸Ð±ÐºÐ¾)
    r"Ð±ÐµÐ· Ð¾Ð¿Ñ‹Ñ‚Ð°",                      # ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¾Ñ„Ñ„ÐµÑ€Ð°
    r"Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ.*Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð¾",            # Ð¾Ð±ÐµÑ‰Ð°Ð½Ð¸Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
    r"Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð° ÑÐ¿Ð»Ð¸Ñ‚",                  # Ñ€ÐµÐºÐ»Ð°Ð¼Ð°
    r"ÑÐ¿Ð»Ð¸Ñ‚ ÑÐ¸ÑÑ‚ÐµÐ¼",                   # HVAC Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°
    r"Ð°ÐºÑ†Ð¸Ñ",                          # ÑÐºÐ¸Ð´ÐºÐ¸
    r"ÑƒÑÐ¿ÐµÐ¹.*ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ",                  # ÑÑ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ
    r"Ð·Ð°Ð±Ñ€Ð¾Ð½Ð¸Ñ€ÑƒÐ¹.*Ð¼ÐµÑÑ‚Ð¾",              # â€œÐ¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµâ€
    r"Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ð² Ð¼ÐµÑÑÐµÐ½Ð´Ð¶ÐµÑ€Ð°Ñ…",          # scam recruitment
    r"ÑÑ‚Ð°Ð²ÐºÐ¸ Ð½Ð° ÑÐ¿Ð¾Ñ€Ñ‚",                # Ð±ÑƒÐºÐ¼ÐµÐºÐµÑ€ÐºÐ°
    r"Ð¿Ñ€Ð¾Ð¼Ð¾ÐºÐ¾Ð´",                       # Ð°ÐºÑ†Ð¸Ð¸/Ð¼Ð¾ÑˆÐµÐ½Ð½Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
    r"Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¿Ñ€ÐµÐ¼Ð¸Ñ",         # Ð¾Ñ„Ñ„ÐµÑ€
    r"Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð°Ñ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ",         # Ð²Ð¾Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ
    r"Ð¿ÐµÐ½ÑÐ¸Ð¾Ð½ÐµÑ€Ð°Ð¼|ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð°Ð¼|Ð´ÐµÐºÑ€ÐµÑ‚Ðµ",  # Ñ†ÐµÐ»ÐµÐ²Ñ‹Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸
    r"Ð¾Ð¿Ð»Ð°Ñ‚Ð° Ð¿Ð¾ Ñ„Ð°ÐºÑ‚Ñƒ",                # Ñ‚Ñ€Ð¸Ð³Ð³ÐµÑ€ Ð¿Ñ€Ð¾Ð´Ð°Ð¶
    r"Ð³Ñ€ÑƒÐ·Ð¾Ð¿ÐµÑ€ÐµÐ²Ð¾Ð·Ðº[Ð°Ð¸]",              # ÑƒÑÐ»ÑƒÐ³Ð¸ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð·ÐºÐ¸
    r"Ð´Ð¾Ð¼Ð°ÑˆÐ½Ð¸Ðµ Ð¿ÐµÑ€ÐµÐµÐ·Ð´Ñ‹",              # Ñ‚Ð¾ Ð¶Ðµ
    r"Ñ€ÐµÐ¼Ð¾Ð½Ñ‚ ÑÐ°Ð½Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ¸",              # ÑˆÐ°Ð±Ð»Ð¾Ð½Ð½Ð°Ñ ÑƒÑÐ»ÑƒÐ³Ð°
    r"Ð¿ÐµÑ€ÐµÐµÐ·Ð´Ñ‹.*Ñ€Ð°ÑÑ‡Ð¸ÑÑ‚ÐºÐ°",            # Ð½Ð°Ð±Ð¾Ñ€ ÑƒÑÐ»ÑƒÐ³
    r"Ð²Ñ‹ÐµÐ·Ð´.*Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ñ‹Ñ…",               # Ð»Ð¾Ð³Ð¸ÑÑ‚Ð¸ÐºÐ°/ÑƒÑÐ»ÑƒÐ³Ð¸
    r"Ð·Ð°Ð±ÐµÑ€Ñ‘Ð¼ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸",               # Ð»Ð¾Ð³Ð¸ÑÑ‚Ð¸ÐºÐ°
    r"ðŸ› |ðŸ›œ|ðŸ“Œ|ðŸ”¥|âœ…|â€¼ï¸|ðŸ“˜|ðŸ“•|ðŸšŒ|ðŸšš|ðŸš€|ðŸŽ",  # ÑÐ¼Ð¾Ð´Ð·Ð¸
    r"[ðŸ…°-ðŸ†ŽðŸ…±ï¸ðŸ†˜ðŸ…¾ï¸ðŸ†š]",                # â€œÐ¾Ð±Ð²Ð¾Ð´ÐºÐ¸â€ Ð±ÑƒÐºÐ²
    r"(?:Ñ€Ð°Ð±Ð¾Ñ‚Ð°|Ð¿Ð¾Ð´Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°)[^.]{0,10}â—", # Ñ€ÐµÐºÐ»Ð°Ð¼Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð²Ð¾ÑÐºÐ»Ð¸Ñ†Ð°Ð½Ð¸ÐµÐ¼
    r"Ñ€Ð°Ð·Ð´Ð°Ñ‡Ð°\s+Ñ„Ð»Ð°ÐµÑ€",                 # Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¾ Ñ„Ð»Ð°ÐµÑ€Ð°Ñ…
    r"Ñ„Ð»Ð°ÐµÑ€",                            # Ð»ÑŽÐ±Ñ‹Ðµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ñ„Ð»Ð°ÐµÑ€Ð¾Ð²
    r"Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ð¸Ð· Ð´Ð¾Ð¼Ð°",                  # Ð¾Ð±Ð¾Ð±Ñ‰Ñ‘Ð½Ð½Ð°Ñ ÑƒÐ´Ð°Ð»Ñ‘Ð½ÐºÐ°
    r"Ð·Ð°Ñ€Ð°Ð±Ð¾Ñ‚(Ð¾Ðº|Ð°Ñ‚ÑŒ)",                 # Ñ‡Ð°ÑÑ‚Ñ‹Ðµ Ñ‚Ñ€Ð¸Ð³Ð³ÐµÑ€Ñ‹ Ð´Ð»Ñ ÑÐ¿Ð°Ð¼Ð°
    r"Ð·Ð°Ð¿Ð¸ÑˆÐ¸ÑÑŒ.*@|Ð½Ð°Ð¿Ð¸ÑˆÐ¸.*@",          # Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³ Ñ‡ÐµÑ€ÐµÐ· Ñ‚ÐµÐ³Ð¸
    r"ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³.*Ð³Ñ€ÑƒÐ¿Ð¿",                 # ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð¸ Ñ€Ð°ÑÑÑ‹Ð»Ð¾Ðº
    r"Ð±Ð¾Ð»ÐµÐµ \d+ Ð³Ñ€ÑƒÐ¿Ð¿",                 # Ñ€Ð°ÑÑÑ‹Ð»Ð¾Ñ‡Ð½Ñ‹Ðµ Ð°Ð½Ð¾Ð½ÑÑ‹
    r"Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°.*Ñ€Ð°Ð·Ð¼ÐµÑ‰Ð°Ð¹",              # Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÑ‹ / Ð±Ð¸Ð·Ð½ÐµÑ-Ñ‡Ð°Ñ‚Ñ‹
    r"Ñ€ÐµÐºÐ»Ð°Ð¼.*Ð³Ñ€ÑƒÐ¿Ð¿",                   # Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð³Ñ€ÑƒÐ¿Ð¿
    r"Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°.*Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸",             # hr-Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°
    r"Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°",      # Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ°Ñ/Ð½ÐµÑ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°
    r"Ñ‚Ð°Ñ€Ð¸Ñ„Ñ‹ Ð½Ð°.*ÑƒÑÐ»ÑƒÐ³Ð¸",              # Ð½Ðµ ÑÐ²ÑÐ·ÑŒ, Ð° Ñ€ÐµÐºÐ»Ð°Ð¼Ð°
    r"Ñ€Ð°ÑÑÑ‹Ð»Ðº",                         # Ñ€Ð°ÑÑÑ‹Ð»ÐºÐ° Ñ€ÐµÐºÐ»Ð°Ð¼Ñ‹
]

# ÐšÐ¾Ð¼Ð¿Ð¸Ð»Ð¸Ñ€ÑƒÐµÐ¼ ÑˆÐ°Ð±Ð»Ð¾Ð½Ñ‹ ÑÐ¿Ð°Ð¼Ð° Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
SPAM_REGEX = [re.compile(p, flags=re.IGNORECASE) for p in SPAM_PATTERNS]


# ÐŸÐ¾Ñ€Ð¾Ð³Ð¾Ð²Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
FUZZ_THRESH     = 85   # Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð´Ð»Ñ fuzzy
MIN_MATCHES     = 1    # Ñ‚Ñ€ÐµÐ±ÑƒÐµÐ¼ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 1 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ ÐºÐ»ÑŽÑ‡Ð°
# Ñ‚Ñ€ÐµÐ±ÑƒÐµÐ¼ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 2 ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð³Ñ€ÑƒÐ¿Ð¿ Ð¿Ñ€Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ð¾Ð²Ð¾Ð¼ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ðµ
MIN_GROUPS      = 2    # Ð¸Ð· Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 2 ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð³Ñ€ÑƒÐ¿Ð¿
MAX_TOKEN_DIST  = 10   # Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼ÐµÐ¶Ð´Ñƒ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼Ð¸ Ð»ÐµÐ¼Ð¼Ð°Ð¼Ð¸


def simple_keyword_match(text: str) -> list[str] | None:
    """
    Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°:
      â€“ ÐžÑ‚ÑÐµÐºÐ°ÐµÑ‚ ÑÐ¿Ð°Ð¼-Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ð°Ð¼/ÑÑÑ‹Ð»ÐºÐ°Ð¼
      â€“ Ð›ÐµÐ¼Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ‚ÐµÐºÑÑ‚ Ñ‡ÐµÑ€ÐµÐ· spaCy
      â€“ ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ multi-word Ð¸ single-word ÐºÐ»ÑŽÑ‡Ð¸ (exact & fuzzy)
      â€“ Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 2 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð¸Ð· Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð³Ñ€ÑƒÐ¿Ð¿
      â€“ Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÑ‚, Ñ‡Ñ‚Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð±Ð»Ð¸Ð·ÐºÐ¾ Ð¿Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ (â‰¤ MAX_TOKEN_DIST Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²)
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÐºÐ»ÑŽÑ‡ÐµÐ¹ Ð¸Ð»Ð¸ None.
    """
    text = str(text)
    t_lower = text.lower()

    # 0) Ð¡Ð¿Ð°Ð¼-Ñ„Ð¸Ð»ÑŒÑ‚Ñ€
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¿Ð°Ð¼ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÑÐºÐ¾Ð¼Ð¿Ð¸Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… regex
    for spam_re in SPAM_REGEX:
        if spam_re.search(t_lower):
            logger.debug(f"ÐžÑ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð¾ ÐºÐ°Ðº ÑÐ¿Ð°Ð¼ Ð¿Ð¾ ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ: {spam_re.pattern}")
            return None
        
    # 1) ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° ÐºÐ»ÑŽÑ‡ÐµÐ¹
    raw_keywords = load_keywords(KEYWORDS_FILE)
    kw_single = {}   # Ð»ÐµÐ¼Ð¼Ð° â†’ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»
    kw_multi  = []   # [(tuple(Ð»ÐµÐ¼Ð¼...), Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»), ...]

    for kw in raw_keywords:
        lemmas = tuple(token.lemma_.lower() for token in nlp(kw) if token.is_alpha)
        if not lemmas:
            continue
        if len(lemmas) == 1:
            kw_single.setdefault(lemmas[0], kw)
        else:
            kw_multi.append((lemmas, kw))

    # 2) Ð›ÐµÐ¼Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°
    doc    = nlp(text)
    lemmas = [token.lemma_.lower() for token in doc if token.is_alpha]
    
    # Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¿Ð¾ Ð»ÐµÐ¼Ð¼Ð°Ð¼ (Ð¸ Ñ„Ñ€Ð°Ð·Ð°Ð¼ Ð¸Ð· Ð»ÐµÐ¼Ð¼)
    matched_groups = set()
    text_lemmas_str = " ".join(lemmas)
    for pattern, group in GROUP_MAP.items():
        if pattern in text_lemmas_str:
            matched_groups.add(group)
            
    matches      = set()
    groups_found = set()
    positions    = []

    # 3) Multi-word match
    for kw_lem, original in kw_multi:
        L = len(kw_lem)
        if L > len(lemmas):
            continue
        for i in range(len(lemmas) - L + 1):
            window = tuple(lemmas[i: i + L])
            if window == kw_lem:
                matches.add(original)
                grp = GROUP_MAP.get(original, "other")
                groups_found.add(grp)
                positions.append(i)
                logger.info(f"Multi-word match '{original}' at pos {i}")
                break

    # 4) Single-word exact match
    for idx, lemma in enumerate(lemmas):
        if lemma in kw_single:
            original = kw_single[lemma]
            matches.add(original)
            grp = GROUP_MAP.get(original, "other")
            groups_found.add(grp)
            positions.append(idx)
            logger.info(f"Single exact match '{original}' at pos {idx}")

    # 5) Single-word fuzzy match (Ñ‚Ñ€ÐµÐ±ÑƒÐµÐ¼ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð´Ð²Ð° Ñ‚Ð°ÐºÐ¸Ñ… ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ)
    fuzzy_hits = 0
    for idx, lemma in enumerate(lemmas):
        for key_lem, original in kw_single.items():
            ratio = fuzz.ratio(lemma, key_lem)
            if ratio >= FUZZ_THRESH:
                fuzzy_hits += 1
                if fuzzy_hits > 1:
                    matches.add(original)
                    grp = GROUP_MAP.get(original, "other")
                    groups_found.add(grp)
                    positions.append(idx)
                    logger.info(
                        f"Fuzzy match '{original}' for lemma='{lemma}' "
                        f"vs key='{key_lem}', ratio={ratio} at pos {idx}"
                    )
                break

    # 6) Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€
    # Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€: Ð´Ð²Ð° Ð¿ÑƒÑ‚Ð¸ Ðº Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¸ÑŽ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
    # 1) Ð”Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€ÑÐ¼Ñ‹Ñ… ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÑÐ»Ð¾Ð²
    if len(matches) >= MIN_MATCHES:
        logger.info(f"ÐŸÑ€ÑÐ¼Ñ‹Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ: matches={matches}")
        return list(matches)
    # 2) Ð”Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð³Ñ€ÑƒÐ¿Ð¿ Ð¸ Ð±Ð»Ð¸Ð·Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸
    if len(matched_groups) >= MIN_GROUPS and len(groups_found) >= MIN_GROUPS \
       and positions and (max(positions) - min(positions) <= MAX_TOKEN_DIST):
        logger.info(
            f"Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€: matched_groups={matched_groups}, "
            f"groups_found={groups_found}, positions={positions}"
        )
        return list(matches)
    # Ð’ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ»ÑƒÑ‡Ð°ÑÑ… Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÑÐµÐ¼
    logger.debug(f"ÐžÑ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¾: matches={matches}, matched_groups={matched_groups}, groups_found={groups_found}, positions={positions}")
    return None